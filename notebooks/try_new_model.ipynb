{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from typing import Any, Dict\n",
    "\n",
    "import lightning as L\n",
    "import plotly.graph_objects as go\n",
    "import rpad.visualize_3d.plots as v3p\n",
    "import torch\n",
    "import torch_geometric.data as tgd\n",
    "from flowbot3d.models.artflownet import artflownet_loss, flow_metrics\n",
    "from online_adaptation.nets.history_nets import *\n",
    "from plotly.subplots import make_subplots\n",
    "from torch import optim\n",
    "from online_adaptation.models.history_tformer import FlowHistoryTformerPredictorTrainingModule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for i in range(16):\n",
    "    d = tgd.Data(\n",
    "        x=None,\n",
    "        pos=torch.rand(torch.randint(1000, tuple()), 3),\n",
    "    )\n",
    "\n",
    "    history = []\n",
    "    flow_history = []\n",
    "    lengths = []\n",
    "    for _ in range(torch.randint(1, 10, tuple())):\n",
    "        N = torch.randint(1000, tuple())\n",
    "        history.append(torch.rand(N, 3))\n",
    "        flow_history.append(torch.rand(N, 3))\n",
    "        lengths.append(N)\n",
    "\n",
    "    d.history = torch.cat(history, dim=0) if len(history) > 0 else None\n",
    "    d.flow_history = torch.cat(flow_history, dim=0) if len(flow_history) > 0 else None\n",
    "    d.lengths = torch.tensor(lengths)\n",
    "    data.append(d)\n",
    "    \n",
    "batch = tgd.Batch.from_data_list(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history_batch(batch):\n",
    "    \"\"\"Extracts a single batch of the history data for encoding, because each history element is processed separately.\"\"\"\n",
    "    history_datas = []\n",
    "    for data in batch.to_data_list():\n",
    "        history_data = []\n",
    "        # Get start/end positions based on lengths.\n",
    "        ixs = [0] + data.lengths.cumsum(0).tolist()\n",
    "        for i in range(len(data.lengths)):\n",
    "            history_data.append(tgd.Data(\n",
    "                x=data.flow_history[ixs[i]:ixs[i + 1]],\n",
    "                pos=data.history[ixs[i]:ixs[i + 1]]\n",
    "            ))\n",
    "        history_datas.extend(history_data)\n",
    "\n",
    "    return tgd.Batch.from_data_list(history_datas)\n",
    "\n",
    "def history_latents_to_nested_list(batch, history_latents):\n",
    "    datas = batch.to_data_list()\n",
    "    history_lengths = [0] + [len(data.lengths) for data in datas]\n",
    "    ixs = torch.tensor(history_lengths).cumsum(0).tolist()\n",
    "    post_encoder_latents = []\n",
    "    for i, data in enumerate(datas):\n",
    "        post_encoder_latents.append(history_latents[ixs[i]:ixs[i + 1]])\n",
    "\n",
    "    return post_encoder_latents\n",
    "\n",
    "history_batch = get_history_batch(batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = pnp.PN2Encoder(in_dim=3, out_dim=256)\n",
    "results = encoder(history_batch)\n",
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_nested_list = history_latents_to_nested_list(batch, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x.shape for x in history_nested_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tformer = nn.Transformer(d_model=256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The list of history latents is the input to the transformer.\n",
    "# Each element in the list is a variable-lenght sequence of latents, with shape [Ni, 256]\n",
    "# The transformer expects the input to have shape [S, N, E], where S is the sequence length, N is the batch size, and E is the embedding size.\n",
    "# We need to pad and mask:\n",
    "\n",
    "# Pad the sequences to the same length, using torch's pad_sequence function.\n",
    "src_padded = nn.utils.rnn.pad_sequence(history_nested_list, batch_first=True, padding_value=0)\n",
    "print(src_padded.shape)\n",
    "\n",
    "# Create a mask for the padded sequences.\n",
    "src_mask = (src_padded != 0).all(-1) # [N, S] \n",
    "print(src_mask.shape)\n",
    "\n",
    "# The transformer expects the input to have shape [S, N, E], where S is the sequence length, N is the batch size, and E is the embedding size.\n",
    "# We need to permute the dimensions.\n",
    "src_padded = src_padded.permute(1, 0, 2)\n",
    "# src_mask = src_mask.permute(1, 0) # No need to transpose...\n",
    "\n",
    "# This is our query vector. It has shape [S, N, E], where S is the sequence length, N is the batch size, and E is the embedding size.\n",
    "tgt = torch.ones(1, 16, 256)\n",
    "\n",
    "# The transformer also expects the input to be of type float.\n",
    "src_padded = src_padded.float()\n",
    "tgt = tgt.float()\n",
    "\n",
    "print(src_padded.shape, tgt.shape, src_mask.shape)\n",
    "\n",
    "# Pass the input through the transformer, with mask and tgt.\n",
    "out = tformer(src_padded, tgt, src_key_padding_mask=src_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_encoder_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "oa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
